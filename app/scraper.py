from bs4 import BeautifulSoup
import requests
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
import subprocess

# BeautifulSoup —Å–∫—Ä–µ–π–ø—ä—Ä
def scrape_with_beautifulsoup(url: str, element: str, class_name: str = None) -> str:
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36"
        }
        response = requests.get(url, headers=headers)
        print(f"BeautifulSoup: GET {url} - Status Code: {response.status_code}")  # ‚úÖ DEBUG

        soup = BeautifulSoup(response.content, "html.parser")

        if class_name and class_name.strip():
            # CSS —Å–µ–ª–µ–∫—Ç–æ—Ä: –Ω–∞–ø—Ä. 'a.primary-link'
            elements = soup.select(f"{element}.{class_name.strip().replace(' ', '.')}")
        else:
            elements = soup.find_all(element)

        result = "\n".join([e.get_text(strip=True) for e in elements])
        print(f"üìå [DEBUG] BeautifulSoup Result: {result}")  # ‚úÖ DEBUG

        return result if result else "‚ö†Ô∏è –ù—è–º–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ –µ–ª–µ–º–µ–Ω—Ç–∏."
    except Exception as e:
        return f"Error: {e}"

# Selenium —Å–∫—Ä–µ–π–ø—ä—Ä
def scrape_with_selenium(url: str, element: str, class_name: str = None) -> str:
    try:
        options = webdriver.ChromeOptions()
        options.add_argument("--headless")  # –°—Ç–∞—Ä—Ç–∏—Ä–∞ –±—Ä–∞—É–∑—ä—Ä–∞ –≤ headless —Ä–µ–∂–∏–º
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

        driver.get(url)
        driver.implicitly_wait(5)

        if class_name:
            elements = driver.find_elements(By.CLASS_NAME, class_name)
        else:
            elements = driver.find_elements(By.TAG_NAME, element)

        result = "\n".join([e.text.strip() for e in elements])
        print(f"Selenium Result: {result}")  # ‚úÖ DEBUG

        driver.quit()
        return result if result else "‚ö†Ô∏è –ù—è–º–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ –µ–ª–µ–º–µ–Ω—Ç–∏."
    except Exception as e:
        return f"Error: {e}"

# Scrapy —Å–∫—Ä–µ–π–ø—ä—Ä (–∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ subprocess)
def scrape_with_scrapy(url: str, element: str, class_name: str = None) -> str:
    try:
        result = subprocess.run(
            [
                "scrapy", "crawl", "example_spider",
                "-a", f"url={url}",
                "-a", f"element={element}",
                "-a", f"class_name={class_name if class_name else ''}"
            ],
            cwd="my_scraper",  # –í–∞–∂–Ω–æ! –°—Ç–∞—Ä—Ç–∏—Ä–∞–º–µ –æ—Ç Scrapy –ø–∞–ø–∫–∞—Ç–∞
            capture_output=True,
            text=True
        )

        output = result.stdout.strip()
        print(f"üìå [DEBUG] Scrapy Output: {output}")  # Debug

        return output if output else "‚ö†Ô∏è –ù—è–º–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ –µ–ª–µ–º–µ–Ω—Ç–∏."
    except Exception as e:
        return f"Error: {e}"
